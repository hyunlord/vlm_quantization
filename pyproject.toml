[project]
name = "vlm-quantization"
version = "0.1.0"
description = "Cross-modal deep hashing with SigLIP2"
requires-python = ">=3.10"
dependencies = [
    "torch>=2.1.0",
    "torchvision>=0.16.0",
    "pytorch-lightning>=2.1.0",
    "transformers>=4.49.0",
    "albumentations>=1.3.0",
    "pycocotools>=2.0.7",
    "pyyaml>=6.0",
    "numpy>=1.24.0",
    "pillow>=10.0.0",
    "scipy>=1.11.0",
    "tqdm>=4.65.0",
    # Hyperparameter Optimization
    "optuna>=3.5.0",
    # Monitoring
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
    "httpx>=0.27.0",
    "psutil>=5.9.0",
    "nvidia-ml-py>=12.0.0",
    "aiosqlite>=0.20.0",
    "websockets>=12.0",
    "pydantic>=2.5.0",
    "markupsafe>=3.0.2",
]

# PyTorch CUDA index â€” cu126 supports both x86_64 and aarch64 (DGX Spark ARM).
# CUDA 13.0 is backward-compatible with cu126 wheels.
[[tool.uv.index]]
name = "pytorch-cu126"
url = "https://download.pytorch.org/whl/cu126"
explicit = true

[tool.uv.sources]
torch = [{ index = "pytorch-cu126" }]
torchvision = [{ index = "pytorch-cu126" }]
