model:
  backbone: "google/siglip2-so400m-patch14-384"
  bit_list: [8, 16, 32, 48, 64, 128]
  hidden_dim: 512
  dropout: 0.1
  freeze_backbone: true

training:
  batch_size: auto  # auto-detect based on GPU VRAM (T4→64, A100→320+)
  max_epochs: 15  # reduced: extra datasets provide more data per epoch
  hash_lr: 1.0e-3
  backbone_lr: 1.0e-5
  weight_decay: 0.01
  warmup_steps: 2000  # increased: ~10x more data needs longer warmup
  gradient_clip_val: 1.0
  accumulate_grad_batches: 4  # overridden when batch_size=auto
  val_check_interval: 0.5  # validate at epoch midpoint + epoch end
  early_stopping_patience: 3  # increased: fewer validations per epoch
  checkpoint_dir: "/content/drive/MyDrive/vlm_quantization/checkpoints"

loss:
  contrastive_weight: 1.0
  ortho_weight: 0.1
  quantization_weight: 0.1
  balance_weight: 0.01
  consistency_weight: 0.5
  lcs_weight: 0.5
  supervised_weight: 0.0  # set > 0 to enable pairwise supervised loss (requires instances_json)
  temperature: 0.07
  ema_decay: 0.99

data:
  data_root: "/content/data/coco"  # local SSD (zips cached on Drive)
  karpathy_json: "/content/data/coco/dataset_coco.json"
  # instances_json: "/content/data/coco/annotations/instances_train2014.json"  # COCO 80-cat labels
  num_workers: 4  # overridden when batch_size=auto
  max_text_length: 64
  image_size: 384
  extra_datasets:
    - jsonl_path: "/content/data/coco_ko/coco_ko.jsonl"
      data_root: "/content/data/coco"
    - jsonl_path: "/content/data/aihub/aihub_71454.jsonl"
      data_root: "/content/data/aihub"
    - jsonl_path: "/content/data/cc3m_ko/cc3m_ko.jsonl"
      data_root: "/content/data/cc3m_ko"

monitor:
  enabled: true
  server_url: "http://localhost:8000"
  log_every_n_steps: 10
