{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLM Cross-Modal Deep Hashing — Colab Launcher\n",
    "\n",
    "Train a cross-modal hashing model (SigLIP2 → 1-bit binary codes) with real-time monitoring dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla T4 (14.7 GB)\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: GPU Check + Google Drive Mount\n",
    "import torch\n",
    "\n",
    "assert torch.cuda.is_available(), \"No GPU detected — switch to a GPU runtime.\"\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "vram = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "print(f\"GPU: {gpu_name} ({vram:.1f} GB)\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "!mkdir -p /content/drive/MyDrive/vlm_quantization/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path '/content/vlm_quantization' already exists and is not an empty directory.\n",
      "/content/vlm_quantization\n",
      ".env loaded from Google Drive\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Clone Repo + Install Dependencies + Load .env from Google Drive\n",
    "!git clone https://github.com/hyunlord/vlm_quantization.git /content/vlm_quantization\n",
    "%cd /content/vlm_quantization\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q pyngrok\n",
    "\n",
    "import os\n",
    "\n",
    "env_path = \"/content/drive/MyDrive/vlm_quantization/.env\"\n",
    "if os.path.exists(env_path):\n",
    "    with open(env_path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith(\"#\") and \"=\" in line:\n",
    "                key, val = line.split(\"=\", 1)\n",
    "                os.environ[key.strip()] = val.strip()\n",
    "    print(f\".env loaded from Google Drive\")\n",
    "else:\n",
    "    print(f\"No .env found at {env_path} — create one with NGROK_AUTH_TOKEN if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Load COCO Captions (zip cached on Drive, extracted to local SSD)\n# Strategy: Drive FUSE can't handle 82K small files reliably.\n# → Cache zips on Drive (single large files = safe)\n# → Extract to local /content/data/coco each session (fast SSD)\nimport os, shutil\n\nDRIVE_CACHE = \"/content/drive/MyDrive/data/coco_zips\"  # zip cache on Drive\nLOCAL_COCO  = \"/content/data/coco\"                      # training reads from here\n\nSOURCES = {\n    \"train2014\": {\n        \"url\": \"http://images.cocodataset.org/zips/train2014.zip\",\n        \"zip\": \"train2014.zip\",\n        \"folder\": \"train2014\",\n    },\n    \"val2014\": {\n        \"url\": \"http://images.cocodataset.org/zips/val2014.zip\",\n        \"zip\": \"val2014.zip\",\n        \"folder\": \"val2014\",\n    },\n    \"annotations\": {\n        \"url\": \"http://images.cocodataset.org/annotations/annotations_trainval2014.zip\",\n        \"zip\": \"annotations_trainval2014.zip\",\n        \"folder\": \"annotations\",\n    },\n}\n\nos.makedirs(DRIVE_CACHE, exist_ok=True)\nos.makedirs(LOCAL_COCO, exist_ok=True)\n\nfor i, (name, src) in enumerate(SOURCES.items(), 1):\n    local_dir = f\"{LOCAL_COCO}/{src['folder']}\"\n    drive_zip = f\"{DRIVE_CACHE}/{src['zip']}\"\n    tmp_zip   = f\"/tmp/{src['zip']}\"\n\n    if os.path.isdir(local_dir):\n        print(f\"  [{i}/3] {name} — already extracted locally, skipping\")\n        continue\n\n    # Try Drive cache first, else download from web\n    if os.path.isfile(drive_zip):\n        print(f\"  [{i}/3] {name} — copying cached zip from Drive...\")\n        shutil.copy2(drive_zip, tmp_zip)\n    else:\n        print(f\"  [{i}/3] {name} — downloading...\")\n        !wget -q --show-progress {src['url']} -O {tmp_zip}\n        # Cache zip to Drive for next session\n        print(f\"         caching zip to Drive...\")\n        shutil.copy2(tmp_zip, drive_zip)\n\n    # Extract to local SSD (fast, no FUSE issues)\n    print(f\"         extracting to local disk...\")\n    !unzip -q {tmp_zip} -d {LOCAL_COCO}/\n    os.remove(tmp_zip)\n\n# Verify\nfor name in (\"train2014\", \"val2014\", \"annotations\"):\n    assert os.path.isdir(f\"{LOCAL_COCO}/{name}\"), f\"{name} missing!\"\nprint(f\"\\nCOCO ready: {LOCAL_COCO}\")\nprint(f\"  train2014: {len(os.listdir(f'{LOCAL_COCO}/train2014')):,} images\")\nprint(f\"  val2014:   {len(os.listdir(f'{LOCAL_COCO}/val2014')):,} images\")"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v20.20.0\n",
      "\n",
      "> frontend@0.1.0 build\n",
      "> next build\n",
      "\n",
      "\u001b[1G\u001b[0K\u001b[35m\u001b[1mAttention\u001b[22m\u001b[39m: Next.js now collects completely anonymous telemetry regarding usage.\n",
      "This information is used to shape Next.js' roadmap and prioritize features.\n",
      "You can learn more, including how to opt-out if you'd not like to participate in this anonymous program, by visiting the following URL:\n",
      "\u001b[36mhttps://nextjs.org/telemetry\u001b[39m\n",
      "\n",
      "\u001b[1m\u001b[38;2;173;127;168m▲ Next.js 16.1.6\u001b[39m\u001b[22m (Turbopack)\n",
      "\n",
      "\u001b[37m\u001b[1m \u001b[22m\u001b[39m Creating an optimized production build ...\n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Compiled successfully in 12.5s\n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Finished TypeScript in 6.5s 36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[?25l\u001b[37m\u001b[1m \u001b[22m\u001b[39m Finished TypeScript in 6.5s  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[37m\u001b[1m \u001b[22m\u001b[39m Finished TypeScript in 6.5s    \n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Collecting page data using 1 worker in 498.8ms m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Collecting page data using 1 worker  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Collecting page data using 1 worker  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[37m\u001b[1m \u001b[22m\u001b[39m Collecting page data using 1 worker in 498.8ms    \n",
      "\u001b[?25l\u001b[37m\u001b[1m \u001b[22m\u001b[39m Generating static pages using 1 worker (0/4)  \u001b[36m[    ]\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Generating static pages using 1 worker (0/4)  \u001b[36m[=   ]\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Generating static pages using 1 worker (4/4) in 301.5ms\n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Finalizing page optimization in 299.4ms m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Finalizing page optimization  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[37m\u001b[1m \u001b[22m\u001b[39m Finalizing page optimization in 299.4ms    \n",
      "\n",
      "\u001b[4mRoute (app)\u001b[24m\n",
      "┌ ○ /\n",
      "└ ○ /_not-found\n",
      "\n",
      "\n",
      "○  (Static)  prerendered as static content\n",
      "\n",
      "\u001b[?25h\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0KFrontend built → monitor/frontend/out/\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Build Frontend (static export)\n",
    "# Next.js 16 requires Node.js >= 18.18.0; Colab's default is too old\n",
    "!curl -fsSL https://deb.nodesource.com/setup_20.x | bash - > /dev/null 2>&1\n",
    "!apt-get -qq install -y nodejs > /dev/null 2>&1\n",
    "!node --version\n",
    "!cd /content/vlm_quantization/monitor/frontend && npm install --silent && npm run build\n",
    "print(\"Frontend built → monitor/frontend/out/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dashboard: https://absorbed-efren-rubbly.ngrok-free.dev\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Start Monitoring Server + ngrok Tunnel\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import uvicorn\n",
    "from pyngrok import ngrok\n",
    "\n",
    "token = os.environ.get(\"NGROK_AUTH_TOKEN\", \"\")\n",
    "if token:\n",
    "    ngrok.set_auth_token(token)\n",
    "\n",
    "def run_server():\n",
    "    uvicorn.run(\"monitor.server.app:app\", host=\"0.0.0.0\", port=8000, log_level=\"warning\")\n",
    "\n",
    "threading.Thread(target=run_server, daemon=True).start()\n",
    "time.sleep(3)\n",
    "\n",
    "tunnel = ngrok.connect(8000)\n",
    "print(f\"\\n Dashboard: {tunnel.public_url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Train (checkpoints → Google Drive)\n",
    "!cd /content/vlm_quantization && git pull && PYTHONPATH=/content/vlm_quantization python train.py --config configs/colab.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 7: (Optional) Optuna Hyperparameter Search\n# Runs 50 trials with 5 epochs each — takes several hours\n# Results DB + best config saved to Google Drive for persistence\nOPTUNA_DIR = \"/content/drive/MyDrive/vlm_quantization/optuna\"\n!mkdir -p {OPTUNA_DIR}\n!cd /content/vlm_quantization && git pull && PYTHONPATH=/content/vlm_quantization python optuna_search.py \\\n    --config configs/colab.yaml \\\n    --n-trials 50 \\\n    --storage sqlite:///{OPTUNA_DIR}/optuna_results.db \\\n    --export-config {OPTUNA_DIR}/best_config.yaml"
  },
  {
   "cell_type": "code",
   "source": "# Cell 8: Retrain with Best Optuna Config\n# Uses the best hyperparameters found by Optuna for full training\nOPTUNA_DIR = \"/content/drive/MyDrive/vlm_quantization/optuna\"\nBEST_CONFIG = f\"{OPTUNA_DIR}/best_config.yaml\"\n\nimport os\nassert os.path.exists(BEST_CONFIG), f\"Best config not found: {BEST_CONFIG}\\nRun Cell 7 (Optuna search) first.\"\n\nprint(\"Best config contents:\")\n!cat {BEST_CONFIG}\nprint(\"\\n--- Starting full training with best hyperparameters ---\\n\")\n!cd /content/vlm_quantization && PYTHONPATH=/content/vlm_quantization python train.py --config {BEST_CONFIG}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}