{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLM Cross-Modal Deep Hashing — Colab Launcher\n",
    "\n",
    "Train a cross-modal hashing model (SigLIP2 → 1-bit binary codes) with real-time monitoring dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla T4 (14.7 GB)\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: GPU Check + Google Drive Mount\n",
    "import torch\n",
    "\n",
    "assert torch.cuda.is_available(), \"No GPU detected — switch to a GPU runtime.\"\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "vram = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "print(f\"GPU: {gpu_name} ({vram:.1f} GB)\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "!mkdir -p /content/drive/MyDrive/vlm_quantization/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path '/content/vlm_quantization' already exists and is not an empty directory.\n",
      "/content/vlm_quantization\n",
      ".env loaded from Google Drive\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Clone Repo + Install Dependencies + Load .env from Google Drive\n",
    "!git clone https://github.com/hyunlord/vlm_quantization.git /content/vlm_quantization\n",
    "%cd /content/vlm_quantization\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q pyngrok\n",
    "\n",
    "import os\n",
    "\n",
    "env_path = \"/content/drive/MyDrive/vlm_quantization/.env\"\n",
    "if os.path.exists(env_path):\n",
    "    with open(env_path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith(\"#\") and \"=\" in line:\n",
    "                key, val = line.split(\"=\", 1)\n",
    "                os.environ[key.strip()] = val.strip()\n",
    "    print(f\".env loaded from Google Drive\")\n",
    "else:\n",
    "    print(f\"No .env found at {env_path} — create one with NGROK_AUTH_TOKEN if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Load COCO Captions (cached on Google Drive)\nimport os\n\nDRIVE_COCO = \"/content/drive/MyDrive/data/coco\"\n\nif os.path.isdir(f\"{DRIVE_COCO}/train2014\") and os.path.isdir(f\"{DRIVE_COCO}/annotations\"):\n    print(f\"COCO ready: {DRIVE_COCO}\")\nelse:\n    print(\"First run: downloading COCO to Google Drive (one-time)...\")\n    !mkdir -p {DRIVE_COCO}\n    !wget -q --show-progress http://images.cocodataset.org/zips/train2014.zip -O /tmp/train2014.zip\n    !wget -q --show-progress http://images.cocodataset.org/zips/val2014.zip -O /tmp/val2014.zip\n    !wget -q --show-progress http://images.cocodataset.org/annotations/annotations_trainval2014.zip -O /tmp/ann.zip\n    !unzip -q /tmp/train2014.zip -d {DRIVE_COCO}/\n    !unzip -q /tmp/val2014.zip -d {DRIVE_COCO}/\n    !unzip -q /tmp/ann.zip -d {DRIVE_COCO}/\n    !rm /tmp/train2014.zip /tmp/val2014.zip /tmp/ann.zip\n    print(\"COCO saved to Google Drive\")"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v20.20.0\n",
      "\n",
      "> frontend@0.1.0 build\n",
      "> next build\n",
      "\n",
      "\u001b[1G\u001b[0K\u001b[35m\u001b[1mAttention\u001b[22m\u001b[39m: Next.js now collects completely anonymous telemetry regarding usage.\n",
      "This information is used to shape Next.js' roadmap and prioritize features.\n",
      "You can learn more, including how to opt-out if you'd not like to participate in this anonymous program, by visiting the following URL:\n",
      "\u001b[36mhttps://nextjs.org/telemetry\u001b[39m\n",
      "\n",
      "\u001b[1m\u001b[38;2;173;127;168m▲ Next.js 16.1.6\u001b[39m\u001b[22m (Turbopack)\n",
      "\n",
      "\u001b[37m\u001b[1m \u001b[22m\u001b[39m Creating an optimized production build ...\n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Compiled successfully in 12.5s\n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Finished TypeScript in 6.5s 36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Running TypeScript  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[?25l\u001b[37m\u001b[1m \u001b[22m\u001b[39m Finished TypeScript in 6.5s  \u001b[36m.\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[37m\u001b[1m \u001b[22m\u001b[39m Finished TypeScript in 6.5s    \n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Collecting page data using 1 worker in 498.8ms m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Collecting page data using 1 worker  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Collecting page data using 1 worker  \u001b[36m...\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[37m\u001b[1m \u001b[22m\u001b[39m Collecting page data using 1 worker in 498.8ms    \n",
      "\u001b[?25l\u001b[37m\u001b[1m \u001b[22m\u001b[39m Generating static pages using 1 worker (0/4)  \u001b[36m[    ]\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Generating static pages using 1 worker (0/4)  \u001b[36m[=   ]\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Generating static pages using 1 worker (4/4) in 301.5ms\n",
      "\u001b[32m\u001b[1m✓\u001b[22m\u001b[39m Finalizing page optimization in 299.4ms m.\u001b[39m\u001b[2K\u001b[1G\u001b[37m\u001b[1m \u001b[22m\u001b[39m Finalizing page optimization  \u001b[36m..\u001b[39m\u001b[2K\u001b[1G\u001b[?25h\u001b[37m\u001b[1m \u001b[22m\u001b[39m Finalizing page optimization in 299.4ms    \n",
      "\n",
      "\u001b[4mRoute (app)\u001b[24m\n",
      "┌ ○ /\n",
      "└ ○ /_not-found\n",
      "\n",
      "\n",
      "○  (Static)  prerendered as static content\n",
      "\n",
      "\u001b[?25h\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0KFrontend built → monitor/frontend/out/\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Build Frontend (static export)\n",
    "# Next.js 16 requires Node.js >= 18.18.0; Colab's default is too old\n",
    "!curl -fsSL https://deb.nodesource.com/setup_20.x | bash - > /dev/null 2>&1\n",
    "!apt-get -qq install -y nodejs > /dev/null 2>&1\n",
    "!node --version\n",
    "!cd /content/vlm_quantization/monitor/frontend && npm install --silent && npm run build\n",
    "print(\"Frontend built → monitor/frontend/out/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dashboard: https://absorbed-efren-rubbly.ngrok-free.dev\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Start Monitoring Server + ngrok Tunnel\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import uvicorn\n",
    "from pyngrok import ngrok\n",
    "\n",
    "token = os.environ.get(\"NGROK_AUTH_TOKEN\", \"\")\n",
    "if token:\n",
    "    ngrok.set_auth_token(token)\n",
    "\n",
    "def run_server():\n",
    "    uvicorn.run(\"monitor.server.app:app\", host=\"0.0.0.0\", port=8000, log_level=\"warning\")\n",
    "\n",
    "threading.Thread(target=run_server, daemon=True).start()\n",
    "time.sleep(3)\n",
    "\n",
    "tunnel = ngrok.connect(8000)\n",
    "print(f\"\\n Dashboard: {tunnel.public_url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Train (checkpoints → Google Drive)\n!cd /content/vlm_quantization && git pull && PYTHONPATH=/content/vlm_quantization python train.py --config configs/colab.yaml"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: (Optional) Manual Checkpoint Backup\n",
    "!cp -r /content/vlm_quantization/checkpoints/* /content/drive/MyDrive/vlm_quantization/checkpoints/ 2>/dev/null || echo \"No local checkpoints to back up (already saving to Drive).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: (Optional) Optuna Hyperparameter Search\n",
    "# Runs 50 trials with 5 epochs each — takes several hours\n",
    "# Results stored in optuna_results.db (SQLite)\n",
    "!cd /content/vlm_quantization && PYTHONPATH=. python optuna_search.py --config configs/colab.yaml --n-trials 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}